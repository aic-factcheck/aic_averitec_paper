\begin{table*}[h]
    \centering
    \begin{tabular}{l | c c c | c c c}
    \hline
    &\multicolumn{3}{c|}{\textbf{Dev Set Results}} & \multicolumn{3}{c}{\textbf{Test Set Results}}  \\
    \textbf{Pipeline Name} & \textbf{Q only} & \textbf{Q+A} & \textbf{AVeriTeC Score} & \textbf{Q only} & \textbf{Q+A} & \textbf{AVeriTeC Score} \\ \hline
    \textbf{mmr+gpt4o-dfewshot-atype}      & 0.46 & 0.29 & 0.42 & 0.46 & 0.32 & 0.50\\
    mmr+gpt4o-dfewshot-tiebrk-atype & 0.46 & 0.29 & 0.41 & 0.46 & 0.32 & 0.50\\
    \averitec{} baseline            & 0.24 & 0.19 & 0.09 & 0.24 & 0.20 & 0.11\\
    \hline
    submission\_dev\_gpt\_likert       & 0.45 & 0.27 & 0.39 \\
    dev\_subquery+gpt4o                & 0.45 & 0.28 & 0.40 \\
    
    dev\_mmr+gpt4o-dfewshot-mock       & 0.45 & 0.28 & 0.41 \\
    submission\_dev\_claude            & 0.43 & 0.28 & 0.35 \\
    submission\_dev\_claude\_likert   & 0.43 & 0.28 & 0.35 \\
    dev\_mmr+gpt4o-dfewshot-gpttiebreaking & 0.38 & 0.24 & 0.31 \\
    dev\_mmr+gpt4o-dfewshot            & 0.45 & 0.29 & 0.42 \\
    dev\_mmr+gpt4o-dfewshot-gpttie-10ev & 0.45 & 0.28 & 0.40 \\
    tuned weightavg gpt4o(?)+DeBERTa          & 0.45 & 0.27 & 0.39 \\
    tuned weightavg Claude(?)+DeBERTa          & 0.43 & 0.28 & 0.36 \\
    dev\_subquery+gpt4o-dfewshot       & 0.45 & 0.29 & 0.42 \\
    claude evidence - DeBERTa cls               & 0.43 & 0.28 & 0.33 \\
    gpt4o evidence - DeBERTa cls               & 0.45 & 0.28 & 0.36 \\
    dev\_mmr+gpt4o                     & 0.45 & 0.28 & 0.38 \\
    MMR+DynamicFewshot RAG            & & & & 0.46 & 0.31 & 0.49 \\
    AIC first test                     & & & & 0.45 & 0.30 & 0.47 \\
    mmr+claude-dynamic-fewshot          & & & & 0.42 & 0.30 & 0.46 \\
    
    \hline
    mmr+llama-dfewshot-tiebrk-atype & 0.46 & 0.27 & 0.36 & 0.47 & 0.29 & 0.42\\
    \bottomrule
    \end{tabular}
    \caption{Comparison of Pipeline Scores on Dev and Test Sets, AVeriTeC scores are @0.25}
    \label{tab:pipeline_scores}
\end{table*}
    