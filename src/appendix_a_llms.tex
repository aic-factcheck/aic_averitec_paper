%!TEX ROOT=../emnlp2023.tex

\section{LLMs}
\label{appendix_sec:llms}

In this section we closely describe the exact usage of the LLMs.
\todo{write}

\subsection{Dynamic Few-shot Learning}
To utilise the few-shot learning framework, we decided to inspire from the baseline system~\cite{averitec2024} and provide the LLMs with a system prompt containing some examples of what we expect the model to do. Our evidence generation component loads the training data, tokenises them using the NLTK word tokenizer~\cite{bird-loper-2004-nltk} and indexes the claims using BM25 Okapi retriever. When the system prompt for our claim was created, we used the previously indexed retriever and searched for the ten most similar claims from the training data. Then, we used these claims' gold questions and answers as the few-shot learning examples. Figure~\ref{lst:llm_system_prompt} shows an example of the system prompt.


\subsection{System Prompt}


\lstset{
    language={},
    basicstyle=\ttfamily\footnotesize\linespread{0.9}, % Smaller font with less spacing
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{green!50!black}\itshape,
    stringstyle=\color{orange},
    numberstyle=\tiny\color{gray},
    numbers=left, % Line numbers on the left
    stepnumber=1, % Line numbers for every line
    numbersep=5pt, % Space between line numbers and code
    tabsize=4, % Size of tabs
    showstringspaces=false, % Don't show spaces in strings
    breaklines=true, % Line wrapping
    breakatwhitespace=true,
    frame=lines, % Add a frame around the code
    captionpos=b, % Caption at the bottom
}

\begin{figure*}
    \begin{lstlisting}[breaklines=true, language={}, frame=single]
You are a professional fact checker, formulate up to 10 questions that cover all the facts needed to validate whether the factual statement (in User message) is true, false, uncertain or a matter of opinion. Each question has one of four answer types: Boolean, Extractive, Abstractive and Unanswerable using the provided sources.
After formulating Your questions and their answers using the provided sources, You evaluate the possible veracity verdicts (Supported claim, Refuted claim, Not enough evidence, or Conflicting evidence/Cherrypicking) given your claim and evidence on a Likert scale (1 - Strongly disagree, 2 - Disagree, 3 - Neutral, 4 - Agree, 5 - Strongly agree). Ultimately, you note the single likeliest veracity verdict according to your best knowledge.
The facts must be coming from these sources, please refer them using assigned IDs:
---
## Source ID: 1 [url]
[context before]
[page content]
[context after]
...

---
## Output formatting
Please, you MUST only print the output in the following output format:
```json
{
    "questions":
        [
            {"question": "<Your first question>", "answer": "<The answer to the Your first question>", "source": "<Single numeric source ID backing the answer for Your first question>", "answer_type":"<The type of first answer>"},
            {"question": "<Your second question>", "answer": "<The answer to the Your second question>", "source": "<Single numeric Source ID backing the answer for Your second question>", "answer_type":"<The type of second answer>"}
        ],
    "claim_veracity": {
        "Supported": "<Likert-scale rating of how much You agree with the 'Supported' veracity classification>",
        "Refuted": "<Likert-scale rating of how much You agree with the 'Refuted' veracity classification>",
        "Not Enough Evidence": "<Likert-scale rating of how much You agree with the 'Not Enough Evidence' veracity classification>",
        "Conflicting Evidence/Cherrypicking": "<Likert-scale rating of how much You agree with the 'Conflicting Evidence/Cherrypicking' veracity classification>"
    },
    "veracity_verdict": "<The suggested veracity classification for the claim>"
}
```
---
## Few-shot learning
You have access to the following few-shot learning examples for questions and answers.:

### Question examples for claim "{example["claim"]}"
"question": "{question}", "answer": "{answer}", "answer_type": "{answer_type}"
...
    \end{lstlisting}
    \caption{System prompt for the LLMs, \averitec{} claim is to be entered into the user prompt. Three dots represent omitted repeating parts of the prompt.}
    \label{lst:llm_system_prompt}
\end{figure*}